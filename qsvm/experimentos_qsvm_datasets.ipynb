{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29af5c91",
   "metadata": {},
   "source": [
    "# Experimentos: Baseline com QSVM\n",
    "\n",
    "Este notebook estabelece baselines de performance com QSVM em datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e355ce5",
   "metadata": {},
   "source": [
    "# Dataset = Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29981d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Ferramentas quânticas \n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler    \n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel  \n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59141e2f",
   "metadata": {},
   "source": [
    "## Loading data and initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80e48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Experimento QSVM com Dataset Completo (30 Features) ---\n",
      "Dataset carregado com 569 amostras e 30 features.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando Experimento QSVM com Dataset Completo (30 Features) ---\")\n",
    "\n",
    "# 2. Carregar os Dados Completos\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "print(f\"Dataset carregado com {X.shape[0]} amostras e {X.shape[1]} features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993b135",
   "metadata": {},
   "source": [
    "## Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbd3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados divididos em treino e teste.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Dados divididos em treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d66f6e",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4104d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados.\n"
     ]
    }
   ],
   "source": [
    "# normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Dados normalizados.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331668d2",
   "metadata": {},
   "source": [
    "# Training QSVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb2e2c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlgorithmError",
     "evalue": "'Sampler job failed!'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit_machine_learning\\state_fidelities\\compute_uncompute.py:222\u001b[39m, in \u001b[36mComputeUncompute._call\u001b[39m\u001b[34m(job, circuits, local, local_opts, _sampler, _post_process_v2, num_virtual_qubits)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     result = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit\\primitives\\primitive_job.py:51\u001b[39m, in \u001b[36mPrimitiveJob.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m._check_submitted()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit\\primitives\\sampler.py:109\u001b[39m, in \u001b[36mSampler._call\u001b[39m\u001b[34m(self, circuits, parameter_values, **run_options)\u001b[39m\n\u001b[32m    107\u001b[39m     qargs_list.append(\u001b[38;5;28mself\u001b[39m._qargs_list[i])\n\u001b[32m    108\u001b[39m probabilities = [\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[43mStatevector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_circuit_to_instruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.probabilities_dict(\n\u001b[32m    110\u001b[39m         qargs=qargs, decimals=\u001b[32m16\u001b[39m\n\u001b[32m    111\u001b[39m     )\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m circ, qargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(bound_circuits, qargs_list)\n\u001b[32m    113\u001b[39m ]\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit\\quantum_info\\states\\statevector.py:101\u001b[39m, in \u001b[36mStatevector.__init__\u001b[39m\u001b[34m(self, data, dims)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (QuantumCircuit, Instruction)):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28mself\u001b[39m._data = \u001b[43mStatevector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_instruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit\\quantum_info\\states\\statevector.py:773\u001b[39m, in \u001b[36mStatevector.from_instruction\u001b[39m\u001b[34m(cls, instruction)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;66;03m# Initialize an the statevector in the all |0> state\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m init = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_qubits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcomplex\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m init[\u001b[32m0\u001b[39m] = \u001b[32m1.0\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 16.0 GiB for an array with shape (1073741824,) and data type complex128",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAlgorithmError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Treinando o modelo\u001b[39;00m\n\u001b[32m     15\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mqsvc_bc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m end_time = time.time()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModelo treinado com sucesso em \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m segundos.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:258\u001b[39m, in \u001b[36mBaseLibSVM.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[LibSVM]\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    257\u001b[39m seed = rnd.randint(np.iinfo(\u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m).max)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mself\u001b[39m.shape_fit_ = X.shape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:317\u001b[39m, in \u001b[36mBaseLibSVM._dense_fit\u001b[39m\u001b[34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m    314\u001b[39m     \u001b[38;5;66;03m# you must store a reference to X to compute the kernel in predict\u001b[39;00m\n\u001b[32m    315\u001b[39m     \u001b[38;5;66;03m# TODO: add keyword copy to copy on demand\u001b[39;00m\n\u001b[32m    316\u001b[39m     \u001b[38;5;28mself\u001b[39m.__Xfit = X\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m0\u001b[39m] != X.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mX.shape[0] should be equal to X.shape[1]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:515\u001b[39m, in \u001b[36mBaseLibSVM._compute_kernel\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m    513\u001b[39m     \u001b[38;5;66;03m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[32m    514\u001b[39m     \u001b[38;5;66;03m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     kernel = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__Xfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sp.issparse(kernel):\n\u001b[32m    517\u001b[39m         kernel = kernel.toarray()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:114\u001b[39m, in \u001b[36mFidelityQuantumKernel.evaluate\u001b[39m\u001b[34m(self, x_vec, y_vec)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_symmetric:\n\u001b[32m    113\u001b[39m     left_parameters, right_parameters, indices = \u001b[38;5;28mself\u001b[39m._get_symmetric_parameterization(x_vec)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     kernel_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_symmetric_kernel_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    118\u001b[39m     left_parameters, right_parameters, indices = \u001b[38;5;28mself\u001b[39m._get_parameterization(x_vec, y_vec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:208\u001b[39m, in \u001b[36mFidelityQuantumKernel._get_symmetric_kernel_matrix\u001b[39m\u001b[34m(self, kernel_shape, left_parameters, right_parameters, indices)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_symmetric_kernel_matrix\u001b[39m(\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    200\u001b[39m     kernel_shape: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     indices: KernelIndices,\n\u001b[32m    204\u001b[39m ) -> np.ndarray:\n\u001b[32m    205\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m    Given a set of parameterization, this computes the kernel matrix.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     kernel_entries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_kernel_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     kernel_matrix = np.ones(kernel_shape)\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (col, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:235\u001b[39m, in \u001b[36mFidelityQuantumKernel._get_kernel_entries\u001b[39m\u001b[34m(self, left_parameters, right_parameters)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_circuits_per_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    229\u001b[39m     job = \u001b[38;5;28mself\u001b[39m._fidelity.run(\n\u001b[32m    230\u001b[39m         [\u001b[38;5;28mself\u001b[39m._feature_map] * num_circuits,\n\u001b[32m    231\u001b[39m         [\u001b[38;5;28mself\u001b[39m._feature_map] * num_circuits,\n\u001b[32m    232\u001b[39m         left_parameters,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    233\u001b[39m         right_parameters,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    234\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     kernel_entries = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.fidelities\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# Determine the number of chunks needed\u001b[39;00m\n\u001b[32m    238\u001b[39m     num_chunks = (\n\u001b[32m    239\u001b[39m         num_circuits + \u001b[38;5;28mself\u001b[39m.max_circuits_per_job - \u001b[32m1\u001b[39m\n\u001b[32m    240\u001b[39m     ) // \u001b[38;5;28mself\u001b[39m.max_circuits_per_job\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit\\primitives\\primitive_job.py:51\u001b[39m, in \u001b[36mPrimitiveJob.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ResultT:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_submitted()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\qiskit_machine_learning\\state_fidelities\\compute_uncompute.py:224\u001b[39m, in \u001b[36mComputeUncompute._call\u001b[39m\u001b[34m(job, circuits, local, local_opts, _sampler, _post_process_v2, num_virtual_qubits)\u001b[39m\n\u001b[32m    222\u001b[39m     result = job.result()\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AlgorithmError(\u001b[33m\"\u001b[39m\u001b[33mSampler job failed!\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_sampler, BaseSamplerV1):\n\u001b[32m    227\u001b[39m     quasi_dists = result.quasi_dists\n",
      "\u001b[31mAlgorithmError\u001b[39m: 'Sampler job failed!'"
     ]
    }
   ],
   "source": [
    "# training qsvm model\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Definindo o mapeamento de características\n",
    "feature_map_bc = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "\n",
    "# Criando o kernel quântico\n",
    "fidelity_kernel_bc = FidelityQuantumKernel(feature_map=feature_map_bc)\n",
    "\n",
    "# Instanciando o modelo QSVC\n",
    "qsvc_bc = QSVC(quantum_kernel=fidelity_kernel_bc, random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "start_time = time.time()\n",
    "qsvc_bc.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Modelo treinado com sucesso em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "predictions = qsvc_bc.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação Final para o QSVM (Breast Cancer, 30 Features) ---\")\n",
    "print(classification_report(y_test, predictions, target_names=load_breast_cancer().target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d910f8",
   "metadata": {},
   "source": [
    "# Dataset = Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6daced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Importando o dataset\\nstudent_performance = \\'student-por.csv\\'\\n\\ndf_student_performance = pd.read_csv(student_performance, sep=\\',\\')  # Lendo o dataset com separador \\',\\'\\n\\n# 3. Replicamos a separação que a biblioteca fazia para nós:\\n# y são as colunas de notas\\ny = df_student_performance[[\\'G1\\', \\'G2\\', \\'G3\\']]\\n# X são TODAS as outras colunas\\nX = df_student_performance.drop(columns=[\\'G1\\', \\'G2\\', \\'G3\\'])\\n\\n# --- Verificações para confirmar que deu tudo certo ---\\nprint(\"--- Dataset carregado localmente com sucesso! ---\")\\nprint(\"Formato das features (X):\", X.shape)\\nprint(\"Formato dos alvos (y):\", y.shape)\\n\\nprint(\"\\n5 primeiras linhas das features (X):\")\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Importando o dataset\n",
    "student_performance = 'student-por.csv'\n",
    "\n",
    "df_student_performance = pd.read_csv(student_performance, sep=',')  # Lendo o dataset com separador ','\n",
    "\n",
    "# 3. Replicamos a separação que a biblioteca fazia para nós:\n",
    "# y são as colunas de notas\n",
    "y = df_student_performance[['G1', 'G2', 'G3']]\n",
    "# X são TODAS as outras colunas\n",
    "X = df_student_performance.drop(columns=['G1', 'G2', 'G3'])\n",
    "\n",
    "# --- Verificações para confirmar que deu tudo certo ---\n",
    "print(\"--- Dataset carregado localmente com sucesso! ---\")\n",
    "print(\"Formato das features (X):\", X.shape)\n",
    "print(\"Formato dos alvos (y):\", y.shape)\n",
    "\n",
    "print(\"\\n5 primeiras linhas das features (X):\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5643ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dimensões dos dados do Student Performance Dataset\\nprint(\"\\nDimensões do Student Performance Dataset:\")\\nprint(f\"X: {X.shape}\")\\nprint(f\"y: {y.shape}\")'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Dimensões dos dados do Student Performance Dataset\n",
    "print(\"\\nDimensões do Student Performance Dataset:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Data cleaning\\n# check for missing values\\nprint(\"\\nVerificando valores ausentes:\")\\nprint(X.isnull().sum())'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Data cleaning\n",
    "# check for missing values\n",
    "print(\"\\nVerificando valores ausentes:\")\n",
    "print(X.isnull().sum())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a1564",
   "metadata": {},
   "source": [
    "## Pré-processamento dataset Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# creating classification targets\\ny_final = np.where(y[\\'G3\\'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\\n# 1 representa aprovado e 0 representa reprovado.\\n# Verificando a distribuição das classes\\nprint(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\\nprint(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# creating classification targets\n",
    "y_final = np.where(y['G3'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\n",
    "# 1 representa aprovado e 0 representa reprovado.\n",
    "# Verificando a distribuição das classes\n",
    "print(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\n",
    "print(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# The dataset seem unbalanced, so it has to be balanced\\n\\n# tranforming text features into numerical features\\nX_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\\n# Verificando as dimensões dos dados após a codificação\\nprint(\"\\nDimensões dos dados após a codificação:\") \\nprint(\"Formato das features (X) antes do processamento:\", X.shape)\\nprint(\"Formato das features (X) após o processamento:\", X_final.shape)\\n# Verificando as primeiras linhas dos dados codificados\\nprint(\"\\nPrimeiras linhas dos dados codificados:\")\\nprint(X_final.head())\\nprint(X_final.dtypes)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# The dataset seem unbalanced, so it has to be balanced\n",
    "\n",
    "# tranforming text features into numerical features\n",
    "X_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\n",
    "# Verificando as dimensões dos dados após a codificação\n",
    "print(\"\\nDimensões dos dados após a codificação:\") \n",
    "print(\"Formato das features (X) antes do processamento:\", X.shape)\n",
    "print(\"Formato das features (X) após o processamento:\", X_final.shape)\n",
    "# Verificando as primeiras linhas dos dados codificados\n",
    "print(\"\\nPrimeiras linhas dos dados codificados:\")\n",
    "print(X_final.head())\n",
    "print(X_final.dtypes)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bd5ca",
   "metadata": {},
   "source": [
    "## Spliting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc65197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=42, stratify=y_final)  # Stratify -> mantém a proporção das classes no split\\n\\nprint(f\"\\nDimensões do conjunto de treino: {X_train.shape}\")\\nprint(f\"Dimensões do conjunto de teste: {X_test.shape}\")'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=42, stratify=y_final)  # Stratify -> mantém a proporção das classes no split\n",
    "\n",
    "print(f\"\\nDimensões do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Dimensões do conjunto de teste: {X_test.shape}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb89b6",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)  \\nX_test_scaled = scaler.transform(X_test)  '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cba89",
   "metadata": {},
   "source": [
    "## Using SMOTE to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbe96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Using SMOTE to balance the dataset\\nfrom imblearn.over_sampling import SMOTE\\n\\nprint(\"Distribuição de classes no treino ANTES do SMOTE:\")\\nprint(pd.Series(y_train).value_counts())\\n\\n# aplying SMOTE\\nsmote = SMOTE(random_state=42)\\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\\n\\n# Verificando o balanceamento DEPOIS do SMOTE\\nprint(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\\nprint(pd.Series(y_train_resampled).value_counts())'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Using SMOTE to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Distribuição de classes no treino ANTES do SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# aplying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Verificando o balanceamento DEPOIS do SMOTE\n",
    "print(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cadab",
   "metadata": {},
   "source": [
    "## Training the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
