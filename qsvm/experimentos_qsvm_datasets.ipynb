{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29af5c91",
   "metadata": {},
   "source": [
    "# Experimentos: Baseline com QSVM\n",
    "\n",
    "Este notebook estabelece baselines de performance com QSVM em datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e355ce5",
   "metadata": {},
   "source": [
    "# Dataset = Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29981d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Ferramentas quânticas \n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler    \n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel  \n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59141e2f",
   "metadata": {},
   "source": [
    "## Loading data and initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d80e48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões dos dados: (569, 30)\n",
      "\n",
      "Distribuição das classes:\n",
      "Classe 0: 212 ocorrências\n",
      "Classe 1: 357 ocorrências\n"
     ]
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)  # Carregando o dataset\n",
    "\n",
    "# Verificando as dimensões dos nossos dados\n",
    "print(f\"Dimensões dos dados: {X.shape}\")\n",
    "\n",
    "\n",
    "# Vendo a distribuição das classes (0 e 1)\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "# Usando numpy para contar as ocorrências de cada classe\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for class_label, count in zip(unique, counts):\n",
    "    print(f\"Classe {class_label}: {count} ocorrências\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[:, :10] \n",
    "\n",
    "idx_class_0 = np.where(y == 0)[0][:100]\n",
    "idx_class_1 = np.where(y == 1)[0][:100]\n",
    "\n",
    "selected_idx = np.concatenate([idx_class_0, idx_class_1])\n",
    "np.random.shuffle(selected_idx)\n",
    "\n",
    "X_small = X_reduced[selected_idx]\n",
    "y_small = y[selected_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993b135",
   "metadata": {},
   "source": [
    "## Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bbd3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões do conjunto de treino: (75, 10)\n",
      "Dimensões do conjunto de teste: (25, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_small, y_small, test_size=0.25, random_state=42, stratify=y_small\n",
    ")\n",
    "print(f\"Dimensões do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Dimensões do conjunto de teste: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d66f6e",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4104d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados normalizados\n"
     ]
    }
   ],
   "source": [
    "# normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Ajusta o scaler e transforma os dados de treino\n",
    "X_test = scaler.transform(X_test)  # Transforma os dados de teste com o mesmo scaler\n",
    "\n",
    "print(\"\\nDados normalizados\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331668d2",
   "metadata": {},
   "source": [
    "# Training QSVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bb2e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado em 135.73 segundos.\n",
      "\n",
      "--- Relatório de Classificação para o QSVM (Breast Cancer) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.78      0.54      0.64        13\n",
      "      benign       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.68        25\n",
      "   macro avg       0.70      0.69      0.68        25\n",
      "weighted avg       0.70      0.68      0.67        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training qsvm model\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Definindo o mapeamento de características\n",
    "feature_map_bc = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "\n",
    "# Criando o kernel quântico\n",
    "fidelity_kernel_bc = FidelityQuantumKernel(feature_map=feature_map_bc)\n",
    "\n",
    "# Instanciando o modelo QSVC\n",
    "qsvc_bc = QSVC(quantum_kernel=fidelity_kernel_bc, random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "start_time = time.time()\n",
    "qsvc_bc.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Modelo treinado em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "# Fazendo previsões\n",
    "qsvc_predictions_bc = qsvc_bc.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"\\n--- Relatório de Classificação para o QSVM (Breast Cancer) ---\")\n",
    "print(classification_report(y_test, qsvc_predictions_bc, target_names=load_breast_cancer().target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d910f8",
   "metadata": {},
   "source": [
    "# Dataset = Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c6daced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Importando o dataset\\nstudent_performance = \\'student-por.csv\\'\\n\\ndf_student_performance = pd.read_csv(student_performance, sep=\\',\\')  # Lendo o dataset com separador \\',\\'\\n\\n# 3. Replicamos a separação que a biblioteca fazia para nós:\\n# y são as colunas de notas\\ny = df_student_performance[[\\'G1\\', \\'G2\\', \\'G3\\']]\\n# X são TODAS as outras colunas\\nX = df_student_performance.drop(columns=[\\'G1\\', \\'G2\\', \\'G3\\'])\\n\\n# --- Verificações para confirmar que deu tudo certo ---\\nprint(\"--- Dataset carregado localmente com sucesso! ---\")\\nprint(\"Formato das features (X):\", X.shape)\\nprint(\"Formato dos alvos (y):\", y.shape)\\n\\nprint(\"\\n5 primeiras linhas das features (X):\")\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Importando o dataset\n",
    "student_performance = 'student-por.csv'\n",
    "\n",
    "df_student_performance = pd.read_csv(student_performance, sep=',')  # Lendo o dataset com separador ','\n",
    "\n",
    "# 3. Replicamos a separação que a biblioteca fazia para nós:\n",
    "# y são as colunas de notas\n",
    "y = df_student_performance[['G1', 'G2', 'G3']]\n",
    "# X são TODAS as outras colunas\n",
    "X = df_student_performance.drop(columns=['G1', 'G2', 'G3'])\n",
    "\n",
    "# --- Verificações para confirmar que deu tudo certo ---\n",
    "print(\"--- Dataset carregado localmente com sucesso! ---\")\n",
    "print(\"Formato das features (X):\", X.shape)\n",
    "print(\"Formato dos alvos (y):\", y.shape)\n",
    "\n",
    "print(\"\\n5 primeiras linhas das features (X):\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6d0d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5643ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dimensões dos dados do Student Performance Dataset\\nprint(\"\\nDimensões do Student Performance Dataset:\")\\nprint(f\"X: {X.shape}\")\\nprint(f\"y: {y.shape}\")'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Dimensões dos dados do Student Performance Dataset\n",
    "print(\"\\nDimensões do Student Performance Dataset:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28a7e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Data cleaning\\n# check for missing values\\nprint(\"\\nVerificando valores ausentes:\")\\nprint(X.isnull().sum())'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Data cleaning\n",
    "# check for missing values\n",
    "print(\"\\nVerificando valores ausentes:\")\n",
    "print(X.isnull().sum())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a1564",
   "metadata": {},
   "source": [
    "## Pré-processamento dataset Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "594cedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# creating classification targets\\ny_final = np.where(y[\\'G3\\'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\\n# 1 representa aprovado e 0 representa reprovado.\\n# Verificando a distribuição das classes\\nprint(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\\nprint(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# creating classification targets\n",
    "y_final = np.where(y['G3'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\n",
    "# 1 representa aprovado e 0 representa reprovado.\n",
    "# Verificando a distribuição das classes\n",
    "print(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\n",
    "print(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16f3f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# The dataset seem unbalanced, so it has to be balanced\\n\\n# tranforming text features into numerical features\\nX_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\\n# Verificando as dimensões dos dados após a codificação\\nprint(\"\\nDimensões dos dados após a codificação:\") \\nprint(\"Formato das features (X) antes do processamento:\", X.shape)\\nprint(\"Formato das features (X) após o processamento:\", X_final.shape)\\n# Verificando as primeiras linhas dos dados codificados\\nprint(\"\\nPrimeiras linhas dos dados codificados:\")\\nprint(X_final.head())\\nprint(X_final.dtypes)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# The dataset seem unbalanced, so it has to be balanced\n",
    "\n",
    "# tranforming text features into numerical features\n",
    "X_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\n",
    "# Verificando as dimensões dos dados após a codificação\n",
    "print(\"\\nDimensões dos dados após a codificação:\") \n",
    "print(\"Formato das features (X) antes do processamento:\", X.shape)\n",
    "print(\"Formato das features (X) após o processamento:\", X_final.shape)\n",
    "# Verificando as primeiras linhas dos dados codificados\n",
    "print(\"\\nPrimeiras linhas dos dados codificados:\")\n",
    "print(X_final.head())\n",
    "print(X_final.dtypes)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bd5ca",
   "metadata": {},
   "source": [
    "## Spliting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfc65197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=42, stratify=y_final)  # Stratify -> mantém a proporção das classes no split\\n\\nprint(f\"\\nDimensões do conjunto de treino: {X_train.shape}\")\\nprint(f\"Dimensões do conjunto de teste: {X_test.shape}\")'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=42, stratify=y_final)  # Stratify -> mantém a proporção das classes no split\n",
    "\n",
    "print(f\"\\nDimensões do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Dimensões do conjunto de teste: {X_test.shape}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb89b6",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d769cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)  \\nX_test_scaled = scaler.transform(X_test)  '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cba89",
   "metadata": {},
   "source": [
    "## Using SMOTE to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cdbe96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Using SMOTE to balance the dataset\\nfrom imblearn.over_sampling import SMOTE\\n\\nprint(\"Distribuição de classes no treino ANTES do SMOTE:\")\\nprint(pd.Series(y_train).value_counts())\\n\\n# aplying SMOTE\\nsmote = SMOTE(random_state=42)\\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\\n\\n# Verificando o balanceamento DEPOIS do SMOTE\\nprint(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\\nprint(pd.Series(y_train_resampled).value_counts())'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Using SMOTE to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Distribuição de classes no treino ANTES do SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# aplying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Verificando o balanceamento DEPOIS do SMOTE\n",
    "print(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cadab",
   "metadata": {},
   "source": [
    "## Training the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
