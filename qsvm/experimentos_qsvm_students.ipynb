{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29af5c91",
   "metadata": {},
   "source": [
    "# Experimentos: Baseline com QSVM\n",
    "\n",
    "Este notebook estabelece baselines de performance com QSVM no dataset Student Performance\n",
    "\n",
    "Usando Seleção de features com base \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3aa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando todas as ferramentas necessárias\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Importando as ferramentas quânticas\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d910f8",
   "metadata": {},
   "source": [
    "# Dataset = Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6daced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Importando o dataset\\nstudent_performance = \\'student-por.csv\\'\\n\\ndf_student_performance = pd.read_csv(student_performance, sep=\\',\\')  # Lendo o dataset com separador \\',\\'\\n\\n# 3. Replicamos a separação que a biblioteca fazia para nós:\\n# y são as colunas de notas\\ny = df_student_performance[[\\'G1\\', \\'G2\\', \\'G3\\']]\\n# X são TODAS as outras colunas\\nX = df_student_performance.drop(columns=[\\'G1\\', \\'G2\\', \\'G3\\'])\\n\\n# --- Verificações para confirmar que deu tudo certo ---\\nprint(\"--- Dataset carregado localmente com sucesso! ---\")\\nprint(\"Formato das features (X):\", X.shape)\\nprint(\"Formato dos alvos (y):\", y.shape)\\n\\nprint(\"\\n5 primeiras linhas das features (X):\")\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o dataset\n",
    "student_performance = 'student-por.csv'\n",
    "\n",
    "df_student_performance = pd.read_csv(student_performance, sep=',')  # Lendo o dataset com separador ','\n",
    "\n",
    "# 3. Replicamos a separação que a biblioteca fazia para nós:\n",
    "# y são as colunas de notas\n",
    "y = df_student_performance[['G1', 'G2', 'G3']]\n",
    "# X são TODAS as outras colunas\n",
    "X = df_student_performance.drop(columns=['G1', 'G2', 'G3'])\n",
    "\n",
    "# --- Verificações para confirmar que deu tudo certo ---\n",
    "print(\"--- Dataset carregado localmente com sucesso! ---\")\n",
    "print(\"Formato das features (X):\", X.shape)\n",
    "print(\"Formato dos alvos (y):\", y.shape)\n",
    "\n",
    "print(\"\\n5 primeiras linhas das features (X):\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5643ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dimensões dos dados do Student Performance Dataset\\nprint(\"\\nDimensões do Student Performance Dataset:\")\\nprint(f\"X: {X.shape}\")\\nprint(f\"y: {y.shape}\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensões dos dados do Student Performance Dataset\n",
    "print(\"\\nDimensões do Student Performance Dataset:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Data cleaning\\n# check for missing values\\nprint(\"\\nVerificando valores ausentes:\")\\nprint(X.isnull().sum())'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# check for missing values\n",
    "print(\"\\nVerificando valores ausentes:\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a1564",
   "metadata": {},
   "source": [
    "## Pré-processamento dataset Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# creating classification targets\\ny_final = np.where(y[\\'G3\\'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\\n# 1 representa aprovado e 0 representa reprovado.\\n# Verificando a distribuição das classes\\nprint(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\\nprint(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating classification targets\n",
    "y_final = np.where(y['G3'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\n",
    "# 1 representa aprovado e 0 representa reprovado.\n",
    "# Verificando a distribuição das classes\n",
    "print(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\n",
    "print(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# The dataset seem unbalanced, so it has to be balanced\\n\\n# tranforming text features into numerical features\\nX_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\\n# Verificando as dimensões dos dados após a codificação\\nprint(\"\\nDimensões dos dados após a codificação:\") \\nprint(\"Formato das features (X) antes do processamento:\", X.shape)\\nprint(\"Formato das features (X) após o processamento:\", X_final.shape)\\n# Verificando as primeiras linhas dos dados codificados\\nprint(\"\\nPrimeiras linhas dos dados codificados:\")\\nprint(X_final.head())\\nprint(X_final.dtypes)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset seem unbalanced, so it has to be balanced\n",
    "\n",
    "# tranforming text features into numerical features\n",
    "X_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\n",
    "# Verificando as dimensões dos dados após a codificação\n",
    "print(\"\\nDimensões dos dados após a codificação:\") \n",
    "print(\"Formato das features (X) antes do processamento:\", X.shape)\n",
    "print(\"Formato das features (X) após o processamento:\", X_final.shape)\n",
    "# Verificando as primeiras linhas dos dados codificados\n",
    "print(\"\\nPrimeiras linhas dos dados codificados:\")\n",
    "print(X_final.head())\n",
    "print(X_final.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bd5ca",
   "metadata": {},
   "source": [
    "## Spliting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc65197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=42, stratify=y_final)  # Stratify -> mantém a proporção das classes no split\\n\\nprint(f\"\\nDimensões do conjunto de treino: {X_train.shape}\")\\nprint(f\"Dimensões do conjunto de teste: {X_test.shape}\")'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, test_size=0.25, random_state=42, stratify=y_final\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f61a33",
   "metadata": {},
   "source": [
    "## Applying feature selection by correlation (30 -> 5 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train_full.copy()\n",
    "train_df[\"aprovado\"] = y_train\n",
    "\n",
    "# Calculamos a correlação das features com a variável alvo\n",
    "correlation = train_df.corr(numeric_only=True)[\"aprovado\"].abs().sort_values(ascending=False)\n",
    "# Selecionando as 5 features mais importantes (excluindo a própria 'aprovado')\n",
    "N_FEATURES = 5\n",
    "top_features = correlation[1:N_FEATURES+1].index.tolist()\n",
    "print(f\"\\nTop {N_FEATURES} features selecionadas com base no treino:\", top_features)\n",
    "\n",
    "# 1c. Filtramos os conjuntos de treino e teste para conter APENAS essas features\n",
    "X_train_selected = X_train_full[top_features]\n",
    "X_test_selected = X_test_full[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb89b6",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)  \\nX_test_scaled = scaler.transform(X_test)  '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "print(\"\\nDados selecionados e normalizados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cba89",
   "metadata": {},
   "source": [
    "## Using SMOTE to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbe96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Using SMOTE to balance the dataset\\nfrom imblearn.over_sampling import SMOTE\\n\\nprint(\"Distribuição de classes no treino ANTES do SMOTE:\")\\nprint(pd.Series(y_train).value_counts())\\n\\n# aplying SMOTE\\nsmote = SMOTE(random_state=42)\\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\\n\\n# Verificando o balanceamento DEPOIS do SMOTE\\nprint(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\\nprint(pd.Series(y_train_resampled).value_counts())'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SMOTE to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Distribuição de classes no treino ANTES do SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# aplying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Verificando o balanceamento DEPOIS do SMOTE\n",
    "print(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cadab",
   "metadata": {},
   "source": [
    "## Training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PASSO 4: Treinamento e Avaliação do QSVM ---\n",
    "num_features = X_train_resampled.shape[1]\n",
    "feature_map_sp = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "fidelity_kernel_sp = FidelityQuantumKernel(feature_map=feature_map_sp)\n",
    "qsvc_sp = QSVC(quantum_kernel=fidelity_kernel_sp, random_state=42)\n",
    "\n",
    "print(f\"\\nModelo QSVC criado para {num_features} features. Iniciando treinamento...\")\n",
    "\n",
    "start_time = time.time()\n",
    "qsvc_sp.fit(X_train_resampled, y_train_resampled)\n",
    "end_time = time.time()\n",
    "print(f\"Modelo treinado em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "qsvc_predictions_sp = qsvc_sp.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação para o QSVM com Seleção de Features (Student Performance) ---\")\n",
    "print(classification_report(y_test, qsvc_predictions_sp, target_names=['Reprovado', 'Aprovado']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
