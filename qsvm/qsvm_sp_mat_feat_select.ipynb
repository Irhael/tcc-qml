{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29af5c91",
   "metadata": {},
   "source": [
    "# Experimentos: Baseline com QSVM\n",
    "\n",
    "Este notebook estabelece baselines de performance com QSVM no dataset Student Performance\n",
    "\n",
    "Usando Seleção de features com base \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3aa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d910f8",
   "metadata": {},
   "source": [
    "# Dataset = Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6daced",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/student-mat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Importando o dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m student_performance = \u001b[33m'\u001b[39m\u001b[33mdata/student-mat.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_student_performance = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_performance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Lendo o dataset com separador ','\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# y são as colunas de notas\u001b[39;00m\n\u001b[32m      7\u001b[39m y = df_student_performance[[\u001b[33m'\u001b[39m\u001b[33mG1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mG2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mG3\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irhael.chagas\\OneDrive - Accenture\\Desktop\\tcc-qml\\tcc_env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/student-mat.csv'"
     ]
    }
   ],
   "source": [
    "# Importando o dataset\n",
    "student_performance = '../data/student-mat.csv'\n",
    "\n",
    "df_student_performance = pd.read_csv(student_performance, sep=',')  # Lendo o dataset com separador ','\n",
    "\n",
    "# y são as colunas de notas\n",
    "y = df_student_performance[['G1', 'G2', 'G3']]\n",
    "# X são todas as outras colunas\n",
    "X = df_student_performance.drop(columns=['G1', 'G2', 'G3'])\n",
    "\n",
    "\n",
    "print(\"--- Dataset carregado localmente com sucesso! ---\")\n",
    "print(\"Formato das features (X):\", X.shape)\n",
    "print(\"Formato dos alvos (y):\", y.shape)\n",
    "\n",
    "print(\"\\n5 primeiras linhas das features (X):\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  higher internet  romantic  famrel  freetime goout Dalc Walc health absences  \n",
       "0    yes       no        no       4         3     4    1    1      3        4  \n",
       "1    yes      yes        no       5         3     3    1    1      3        2  \n",
       "2    yes      yes        no       4         3     2    2    3      3        6  \n",
       "3    yes      yes       yes       3         2     2    1    1      5        0  \n",
       "4    yes       no        no       4         3     2    1    2      5        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5643ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensões do Student Performance Dataset:\n",
      "X: (649, 30)\n",
      "y: (649, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dimensões dos dados do Student Performance Dataset\n",
    "print(\"\\nDimensões do Student Performance Dataset:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando valores ausentes:\n",
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# check for missing values\n",
    "print(\"\\nVerificando valores ausentes:\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a1564",
   "metadata": {},
   "source": [
    "## Pré-processamento dataset Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuição das classes (Aprovado/Reprovado):\n",
      "1    549\n",
      "0    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# creating classification targets\n",
    "y_final = np.where(y['G3'] >= 10, 1, 0)  # Convertendo a nota final em uma classificação binária (aprovado/reprovado). Usando 10 como o limite de aprovação.\n",
    "# 1 representa aprovado e 0 representa reprovado.\n",
    "# Verificando a distribuição das classes\n",
    "print(\"\\nDistribuição das classes (Aprovado/Reprovado):\")\n",
    "print(pd.Series(y_final).value_counts()) # Contando as ocorrências de cada classe. usando pd.Series para criar uma série pandas a partir do array numpy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensões dos dados após a codificação:\n",
      "Formato das features (X) antes do processamento: (649, 30)\n",
      "Formato das features (X) após o processamento: (649, 39)\n",
      "\n",
      "Primeiras linhas dos dados codificados:\n",
      "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
      "0   18     4     4           2          2         0       4         3      4   \n",
      "1   17     1     1           1          2         0       5         3      3   \n",
      "2   15     1     1           1          2         0       4         3      2   \n",
      "3   15     4     2           1          3         0       3         2      2   \n",
      "4   16     3     3           1          2         0       4         3      2   \n",
      "\n",
      "   Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  famsup_yes  \\\n",
      "0     1  ...             True           False           True       False   \n",
      "1     1  ...            False           False          False        True   \n",
      "2     2  ...             True           False           True       False   \n",
      "3     1  ...             True           False          False        True   \n",
      "4     1  ...            False           False          False        True   \n",
      "\n",
      "   paid_yes  activities_yes  nursery_yes  higher_yes  internet_yes  \\\n",
      "0     False           False         True        True         False   \n",
      "1     False           False        False        True          True   \n",
      "2     False           False         True        True          True   \n",
      "3     False            True         True        True          True   \n",
      "4     False           False         True        True         False   \n",
      "\n",
      "   romantic_yes  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3          True  \n",
      "4         False  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "age                  int64\n",
      "Medu                 int64\n",
      "Fedu                 int64\n",
      "traveltime           int64\n",
      "studytime            int64\n",
      "failures             int64\n",
      "famrel               int64\n",
      "freetime             int64\n",
      "goout                int64\n",
      "Dalc                 int64\n",
      "Walc                 int64\n",
      "health               int64\n",
      "absences             int64\n",
      "school_MS             bool\n",
      "sex_M                 bool\n",
      "address_U             bool\n",
      "famsize_LE3           bool\n",
      "Pstatus_T             bool\n",
      "Mjob_health           bool\n",
      "Mjob_other            bool\n",
      "Mjob_services         bool\n",
      "Mjob_teacher          bool\n",
      "Fjob_health           bool\n",
      "Fjob_other            bool\n",
      "Fjob_services         bool\n",
      "Fjob_teacher          bool\n",
      "reason_home           bool\n",
      "reason_other          bool\n",
      "reason_reputation     bool\n",
      "guardian_mother       bool\n",
      "guardian_other        bool\n",
      "schoolsup_yes         bool\n",
      "famsup_yes            bool\n",
      "paid_yes              bool\n",
      "activities_yes        bool\n",
      "nursery_yes           bool\n",
      "higher_yes            bool\n",
      "internet_yes          bool\n",
      "romantic_yes          bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The dataset seem unbalanced, so it has to be balanced\n",
    "\n",
    "# tranforming text features into numerical features\n",
    "X_final = pd.get_dummies(X, drop_first=True)  # Convertendo variáveis categóricas em variáveis dummy # drop_first=True evita a armadilha da variável fictícia\n",
    "# Verificando as dimensões dos dados após a codificação\n",
    "print(\"\\nDimensões dos dados após a codificação:\") \n",
    "print(\"Formato das features (X) antes do processamento:\", X.shape)\n",
    "print(\"Formato das features (X) após o processamento:\", X_final.shape)\n",
    "# Verificando as primeiras linhas dos dados codificados\n",
    "print(\"\\nPrimeiras linhas dos dados codificados:\")\n",
    "print(X_final.head())\n",
    "print(X_final.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bd5ca",
   "metadata": {},
   "source": [
    "## Spliting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc65197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, test_size=0.25, random_state=42, stratify=y_final\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f61a33",
   "metadata": {},
   "source": [
    "## Applying feature selection by correlation (30 -> 5 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 features selecionadas com base no treino: ['failures', 'higher_yes', 'school_MS', 'Medu', 'studytime']\n"
     ]
    }
   ],
   "source": [
    "train_df = X_train_full.copy()\n",
    "train_df[\"aprovado\"] = y_train\n",
    "\n",
    "# Calculamos a correlação das features com a variável alvo\n",
    "correlation = train_df.corr(numeric_only=True)[\"aprovado\"].abs().sort_values(ascending=False)\n",
    "# Selecionando as 5 features mais importantes (excluindo a própria 'aprovado')\n",
    "N_FEATURES = 5\n",
    "top_features = correlation[1:N_FEATURES+1].index.tolist()\n",
    "print(f\"\\nTop {N_FEATURES} features selecionadas com base no treino:\", top_features)\n",
    "\n",
    "\n",
    "X_train_selected = X_train_full[top_features]\n",
    "X_test_selected = X_test_full[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb89b6",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados selecionados e normalizados.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "print(\"\\nDados selecionados e normalizados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cba89",
   "metadata": {},
   "source": [
    "## Using SMOTE to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbe96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de classes no treino ANTES do SMOTE:\n",
      "1    411\n",
      "0     75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição de classes no treino DEPOIS do SMOTE:\n",
      "1    411\n",
      "0    411\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Distribuição de classes no treino ANTES do SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# aplying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Verificando o balanceamento DEPOIS do SMOTE\n",
    "print(\"\\nDistribuição de classes no treino DEPOIS do SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cadab",
   "metadata": {},
   "source": [
    "## Training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bde4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo QSVC criado para 5 features. Iniciando treinamento...\n",
      "Modelo treinado em 858.06 segundos.\n",
      "\n",
      "--- Relatório de Classificação para o QSVM com Seleção de Features (Student Performance) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Reprovado       0.31      0.56      0.40        25\n",
      "    Aprovado       0.91      0.78      0.84       138\n",
      "\n",
      "    accuracy                           0.74       163\n",
      "   macro avg       0.61      0.67      0.62       163\n",
      "weighted avg       0.82      0.74      0.77       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinamento e Avaliação do QSVM\n",
    "num_features = X_train_resampled.shape[1]\n",
    "feature_map_sp = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "fidelity_kernel_sp = FidelityQuantumKernel(feature_map=feature_map_sp)\n",
    "qsvc_sp = QSVC(quantum_kernel=fidelity_kernel_sp, random_state=42)\n",
    "\n",
    "print(f\"\\nModelo QSVC criado para {num_features} features. Iniciando treinamento...\")\n",
    "\n",
    "start_time = time.time()\n",
    "qsvc_sp.fit(X_train_resampled, y_train_resampled)\n",
    "end_time = time.time()\n",
    "print(f\"Modelo treinado em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "qsvc_predictions_sp = qsvc_sp.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação para o QSVM com Seleção de Features (Student Performance) ---\")\n",
    "print(classification_report(y_test, qsvc_predictions_sp, target_names=['Reprovado', 'Aprovado']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
